# naked_llama
build llama inference compute from scrath, only using torch/numpy base ops
